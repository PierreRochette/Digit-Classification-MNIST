{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train) , (X_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette ligne retourne quatre tableaux Numpy : \n",
    "- **X_train :** Les images d'entraînements pour entrainer le modèle. Chaque image est représentée comme une matrice de 28x28 pixels en niveaux de gris. \n",
    "- **y_train :** Les labels d'entraînements = valeurs réelles (0 à 9) correspondant aux images d'entraînement. \n",
    "- **X_test :** Les images de test, utilisées pour évaluer la performance du modèle après l'entraînement. Chaque image est une matrice de 28x28. \n",
    "- **y_test :**: Les labels des tests. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train) # Renvoit le nombre d'images d'entraînement (60 000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test) # Renvoit le nombre d'images de test (10 000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape # Renvoit 28x28 (taille de la matrice de cette image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0] # Renvoit la matrice de la première image de X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7b75602dab40>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(X_train[0]) # Affiche l'image (en niveaux de gris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.uint8(5)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0] # Affiche le label de l'image 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape # Affiche (60000, 28, 28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce morceau de code décrit la dimension des données d'entraînement dans le dataset MINST.\n",
    "- Il y a 60 000 images dans le jeu de données d'entraînement. \n",
    "- Chaque image a une hauteur de 28 px\n",
    "- Chaque image a une largeur de 28 px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code ajouté après avoir initié le modèle et l'avoir entraîné une première \n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Le code précédent est de la normalisation**\n",
    "\n",
    "Les images du dataset MNIST sont en niveau de gris, et chaque pixel prend une valeur entre 0 et 255. En divisant chaque pixel par 255, les valeurs sont réduites à un intervalle de 0 à 1. Cela permet : \n",
    "- Une meilleure convergence lors de l'entraînement\n",
    "- Réduction de disparités dans les features \n",
    "- Stabilité numérique\n",
    "\n",
    "En divisant par 255, on aide le modèle à mieux apprendre en ajustant les données d'entrée à une échelle plus maniable et en favorisant un entraînement plus stable et efficace. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_flattened = X_train.reshape(len(X_train), 28 * 28)\n",
    "X_test_flattened = X_test.reshape(len(X_test), 28 * 28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilise une méthode de numpy utilisée pour donner une nouvelle forme à un tableau sans changer ses données. \n",
    "Ce code change la forme de chaque image de 28x28 (une matrice) en un vecteur de 784 pixels (28 multiplié par 28). \n",
    "X_train_flattened aura une forme de (60000, 784)\n",
    "\n",
    "**L'opération de flattening transforme une liste en deux dimensions (matrice) en une liste en une dimension (vecteur)**. \n",
    "\n",
    "Chaque image dans le dataset MNIST est initialement représentée comme une matrice 2D de 28x28. Chaque entrée dans cette matrice représente l'intensité d'un pixel en niveau de gris. En applatissant cette matrice, on la convertit en un vecteur de 784 éléments (28 x 28). Cette transformation est essentielle pour utiliser les images avec des modèles qui ne gèrent pas les données sous forme de matrice 2D. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_flattened.shape # Outputs (60000, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
       "       0.07058824, 0.49411765, 0.53333333, 0.68627451, 0.10196078,\n",
       "       0.65098039, 1.        , 0.96862745, 0.49803922, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.11764706, 0.14117647, 0.36862745, 0.60392157,\n",
       "       0.66666667, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.88235294, 0.6745098 , 0.99215686, 0.94901961,\n",
       "       0.76470588, 0.25098039, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.19215686, 0.93333333,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.98431373, 0.36470588,\n",
       "       0.32156863, 0.32156863, 0.21960784, 0.15294118, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.07058824, 0.85882353, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.77647059, 0.71372549,\n",
       "       0.96862745, 0.94509804, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.31372549, 0.61176471, 0.41960784, 0.99215686, 0.99215686,\n",
       "       0.80392157, 0.04313725, 0.        , 0.16862745, 0.60392157,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
       "       0.00392157, 0.60392157, 0.99215686, 0.35294118, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.54509804,\n",
       "       0.99215686, 0.74509804, 0.00784314, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.04313725, 0.74509804, 0.99215686,\n",
       "       0.2745098 , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.1372549 , 0.94509804, 0.88235294, 0.62745098,\n",
       "       0.42352941, 0.00392157, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.31764706, 0.94117647, 0.99215686, 0.99215686, 0.46666667,\n",
       "       0.09803922, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.17647059,\n",
       "       0.72941176, 0.99215686, 0.99215686, 0.58823529, 0.10588235,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.0627451 , 0.36470588,\n",
       "       0.98823529, 0.99215686, 0.73333333, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.97647059, 0.99215686,\n",
       "       0.97647059, 0.25098039, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.18039216, 0.50980392,\n",
       "       0.71764706, 0.99215686, 0.99215686, 0.81176471, 0.00784314,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.15294118,\n",
       "       0.58039216, 0.89803922, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.98039216, 0.71372549, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.09411765, 0.44705882, 0.86666667, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.78823529, 0.30588235, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.09019608, 0.25882353, 0.83529412, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.77647059, 0.31764706,\n",
       "       0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.07058824, 0.67058824, 0.85882353,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.76470588,\n",
       "       0.31372549, 0.03529412, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.21568627, 0.6745098 ,\n",
       "       0.88627451, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.95686275, 0.52156863, 0.04313725, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.53333333, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.83137255, 0.52941176, 0.51764706, 0.0627451 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_flattened[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pierre/Documents/EPITECH/Digit-Classification-MNIST/bootstrap-ia/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 766us/step - accuracy: 0.8178 - loss: 0.7078\n",
      "Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 796us/step - accuracy: 0.9123 - loss: 0.3161\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 748us/step - accuracy: 0.9196 - loss: 0.2903\n",
      "Epoch 4/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 781us/step - accuracy: 0.9219 - loss: 0.2769\n",
      "Epoch 5/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 730us/step - accuracy: 0.9263 - loss: 0.2638\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7b75602f5e50>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(10, input_shape=(784,),activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam', \n",
    "    loss='sparse_categorical_crossentropy', \n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.fit(X_train_flattened, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La normalisation a permis d'avoir une meilleure accuracy !\n",
    "L'output précédent permet d'évaluer l'accuracy du modèle sur le dataset d'entraînement. Il faut maintenant l'utiliser sur le dataset de test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bootstrap-ia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
